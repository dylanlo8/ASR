{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: pandas in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: urllib3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: torchaudio in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: scipy in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: tqdm in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: matplotlib in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: transformers in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: deepcut in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (0.7.0.0)\n",
      "Requirement already satisfied: jiwer in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (3.0.4)\n",
      "Requirement already satisfied: pydub in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (0.25.1)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from deepcut) (2.16.1)\n",
      "Requirement already satisfied: scikit-learn in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from deepcut) (1.4.2)\n",
      "Requirement already satisfied: h5py in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from deepcut) (3.11.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from jiwer) (3.9.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (69.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow>=2.0.0->deepcut) (0.37.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from scikit-learn->deepcut) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from scikit-learn->deepcut) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->deepcut) (0.43.0)\n",
      "Requirement already satisfied: rich in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.0.0->deepcut) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.0.0->deepcut) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.0.0->deepcut) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.0.0->deepcut) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.0.0->deepcut) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.0.0->deepcut) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow>=2.0.0->deepcut) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow>=2.0.0->deepcut) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow>=2.0.0->deepcut) (0.1.2)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-16.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install numpy torch pandas urllib3 torchaudio scipy tqdm matplotlib transformers deepcut jiwer pydub evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dhuser/Desktop/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 10:52:34.122066: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-15 10:52:34.155424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-15 10:52:34.678727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/dhuser/Desktop/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import deepcut\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import tarfile\n",
    "import whisper\n",
    "import torchaudio\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from jiwer import cer\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Audio and Subtitles Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory(directory):\n",
    "    file_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        # Only pick up files with .txt extensions (transcript)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_list.append(filename.replace(\".txt\", \"\"))\n",
    "    return file_list\n",
    "\n",
    "def get_reference_df(audio_txt_file):\n",
    "    columns = [\"start_time\", \"end_time\", \"reference\"]\n",
    "    txt_file_path = os.path.join(\"data\", audio_txt_file + \".txt\")\n",
    "    # Read the text file into a DataFrame\n",
    "    df = pd.read_csv(txt_file_path, sep=\"\\t\", header=None, names=columns, quoting=3)\n",
    "\n",
    "    # Add file name\n",
    "    df.insert(0, 'file_name', pd.Series([audio_txt_file] * len(df)))\n",
    "\n",
    "    # Remove quotation marks\n",
    "    df['reference'] = df['reference'].apply(lambda x : x.replace('\"',\"\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def trim_wav_by_timestamps(wav_file_name, reference_df):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = \"data/sub/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    wav_file = os.path.join(\"data\", wav_file_name + \".wav\") # get into data file\n",
    "    \n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "    \n",
    "    def trim_segments(row):\n",
    "        start_ms = float(row['start_time']) * 1000  # Convert start time to milliseconds\n",
    "        end_ms = float(row['end_time']) * 1000      # Convert end time to milliseconds\n",
    "        trimmed_segment = audio[start_ms:end_ms]\n",
    "    \n",
    "        return trimmed_segment\n",
    "    \n",
    "    # Iterate over timestamps and trim the audio\n",
    "    for i, row in reference_df.iterrows():\n",
    "        trimmed_segment = trim_segments(row)\n",
    "        output_file = os.path.join(output_dir, wav_file_name + \"_\" f\"trimmed_segment_{i+1}.wav\")\n",
    "        trimmed_segment.export(output_file, format=\"wav\")\n",
    "        reference_df.at[i, 'trimmed_segment_path'] = output_file\n",
    "    \n",
    "    return reference_df\n",
    "\n",
    "def filter_english_subs(reference_df):\n",
    "    # Helper function that is applied across the rows to filter english text only\n",
    "    def filter_english_only(text):\n",
    "        # Define a regex pattern to match English words\n",
    "        english_pattern = re.compile(r'\\b[A-Za-z]+\\b')\n",
    "        # Find all English words in the text\n",
    "        english_words = english_pattern.findall(text)\n",
    "        # Join the English words into a single string\n",
    "        english_text = ' '.join(english_words)\n",
    "        return english_text\n",
    "\n",
    "    reference_df['reference'] = reference_df['reference'].apply(filter_english_only)\n",
    "\n",
    "    return reference_df\n",
    "\n",
    "def get_combined_audio_table(file_names):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        # Reads the transcript dataframe which has the start_time, end_time of each transcript\n",
    "        reference_df = get_reference_df(file_name)\n",
    "\n",
    "        # Retain only English translations in the transcript (reference) column\n",
    "        reference_df = filter_english_subs(reference_df)\n",
    "\n",
    "        # Trims all the .wav file according to the subtitles start_time and end_time\n",
    "        reference_df = trim_wav_by_timestamps(file_name, reference_df)\n",
    "        \n",
    "        # Append the processed DataFrame to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, reference_df], ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ScnwIYdmqYw', 'De95Osq7p1c', 'GWXwTJM68hk']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>reference</th>\n",
       "      <th>trimmed_segment_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>0.708</td>\n",
       "      <td>4.350</td>\n",
       "      <td>Hello this is Dr Supawat from Eternity Clinic</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>4.350</td>\n",
       "      <td>9.554</td>\n",
       "      <td>today we are going to give you some knowledge ...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>9.554</td>\n",
       "      <td>11.554</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>21.000</td>\n",
       "      <td>25.426</td>\n",
       "      <td>Many patients say that the injection of foreig...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>25.426</td>\n",
       "      <td>26.393</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>784.274</td>\n",
       "      <td>786.203</td>\n",
       "      <td>Because it s a special order from me</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_351.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>786.235</td>\n",
       "      <td>788.016</td>\n",
       "      <td>Take a closer look</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_352.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>788.329</td>\n",
       "      <td>790.116</td>\n",
       "      <td>Please leave an answer within</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_353.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>790.141</td>\n",
       "      <td>792.530</td>\n",
       "      <td>Wednesday April</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_354.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>792.555</td>\n",
       "      <td>794.383</td>\n",
       "      <td>at</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_355.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  start_time  end_time  \\\n",
       "0    ScnwIYdmqYw       0.708     4.350   \n",
       "1    ScnwIYdmqYw       4.350     9.554   \n",
       "2    ScnwIYdmqYw       9.554    11.554   \n",
       "3    ScnwIYdmqYw      21.000    25.426   \n",
       "4    ScnwIYdmqYw      25.426    26.393   \n",
       "..           ...         ...       ...   \n",
       "579  GWXwTJM68hk     784.274   786.203   \n",
       "580  GWXwTJM68hk     786.235   788.016   \n",
       "581  GWXwTJM68hk     788.329   790.116   \n",
       "582  GWXwTJM68hk     790.141   792.530   \n",
       "583  GWXwTJM68hk     792.555   794.383   \n",
       "\n",
       "                                             reference  \\\n",
       "0        Hello this is Dr Supawat from Eternity Clinic   \n",
       "1    today we are going to give you some knowledge ...   \n",
       "2                                    Into the genitals   \n",
       "3    Many patients say that the injection of foreig...   \n",
       "4                                    Into the genitals   \n",
       "..                                                 ...   \n",
       "579               Because it s a special order from me   \n",
       "580                                 Take a closer look   \n",
       "581                      Please leave an answer within   \n",
       "582                                    Wednesday April   \n",
       "583                                                 at   \n",
       "\n",
       "                             trimmed_segment_path  \n",
       "0      data/sub/ScnwIYdmqYw_trimmed_segment_1.wav  \n",
       "1      data/sub/ScnwIYdmqYw_trimmed_segment_2.wav  \n",
       "2      data/sub/ScnwIYdmqYw_trimmed_segment_3.wav  \n",
       "3      data/sub/ScnwIYdmqYw_trimmed_segment_4.wav  \n",
       "4      data/sub/ScnwIYdmqYw_trimmed_segment_5.wav  \n",
       "..                                            ...  \n",
       "579  data/sub/GWXwTJM68hk_trimmed_segment_351.wav  \n",
       "580  data/sub/GWXwTJM68hk_trimmed_segment_352.wav  \n",
       "581  data/sub/GWXwTJM68hk_trimmed_segment_353.wav  \n",
       "582  data/sub/GWXwTJM68hk_trimmed_segment_354.wav  \n",
       "583  data/sub/GWXwTJM68hk_trimmed_segment_355.wav  \n",
       "\n",
       "[584 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "file_names = list_files_in_directory(directory)\n",
    "print(file_names)\n",
    "combined_df = get_combined_audio_table(file_names)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['segment_duration'] = combined_df.apply(lambda x : x['end_time'] - x['start_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    584.000000\n",
       "mean       2.102329\n",
       "std        1.055981\n",
       "min        0.500000\n",
       "25%        1.383000\n",
       "50%        1.858500\n",
       "75%        2.475250\n",
       "max        7.442000\n",
       "Name: segment_duration, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['segment_duration'].describe() # All audio segments are under 10s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Translation with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Thai\"\n",
    "options = dict(language=language, beam_size=5, best_of=5)\n",
    "translate_options = dict(task=\"translate\", **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_transcription(row):\n",
    "    segment_wavfile = row['trimmed_segment_path']\n",
    "    transcription = model.transcribe(segment_wavfile, **translate_options)['text']\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = combined_df.apply(map_transcription, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['hypothesis'] = transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>reference</th>\n",
       "      <th>trimmed_segment_path</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>segment_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>0.708</td>\n",
       "      <td>4.350</td>\n",
       "      <td>Hello this is Dr Supawat from Eternity Clinic</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_1.wav</td>\n",
       "      <td>Hello, I'm Dr. Superwat from Eternity Clinic.</td>\n",
       "      <td>3.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>4.350</td>\n",
       "      <td>9.554</td>\n",
       "      <td>today we are going to give you some knowledge ...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_2.wav</td>\n",
       "      <td>Today, I'm going to tell you about Synthetic ...</td>\n",
       "      <td>5.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>9.554</td>\n",
       "      <td>11.554</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_3.wav</td>\n",
       "      <td>menopause.</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>21.000</td>\n",
       "      <td>25.426</td>\n",
       "      <td>Many patients say that the injection of foreig...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_4.wav</td>\n",
       "      <td>many patients have also diagnosed that it's i...</td>\n",
       "      <td>4.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>25.426</td>\n",
       "      <td>26.393</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_5.wav</td>\n",
       "      <td></td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>784.274</td>\n",
       "      <td>786.203</td>\n",
       "      <td>Because it s a special order from me</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_351.wav</td>\n",
       "      <td>Especially when it comes to special events.</td>\n",
       "      <td>1.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>786.235</td>\n",
       "      <td>788.016</td>\n",
       "      <td>Take a closer look</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_352.wav</td>\n",
       "      <td>Please take a good look at it.</td>\n",
       "      <td>1.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>788.329</td>\n",
       "      <td>790.116</td>\n",
       "      <td>Please leave an answer within</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_353.wav</td>\n",
       "      <td>ENG SUB by JayBL</td>\n",
       "      <td>1.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>790.141</td>\n",
       "      <td>792.530</td>\n",
       "      <td>Wednesday April</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_354.wav</td>\n",
       "      <td>ENG SUBBED BY GIRLS' GENERATION ENG SUB</td>\n",
       "      <td>2.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>792.555</td>\n",
       "      <td>794.383</td>\n",
       "      <td>at</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_355.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  start_time  end_time  \\\n",
       "0    ScnwIYdmqYw       0.708     4.350   \n",
       "1    ScnwIYdmqYw       4.350     9.554   \n",
       "2    ScnwIYdmqYw       9.554    11.554   \n",
       "3    ScnwIYdmqYw      21.000    25.426   \n",
       "4    ScnwIYdmqYw      25.426    26.393   \n",
       "..           ...         ...       ...   \n",
       "579  GWXwTJM68hk     784.274   786.203   \n",
       "580  GWXwTJM68hk     786.235   788.016   \n",
       "581  GWXwTJM68hk     788.329   790.116   \n",
       "582  GWXwTJM68hk     790.141   792.530   \n",
       "583  GWXwTJM68hk     792.555   794.383   \n",
       "\n",
       "                                             reference  \\\n",
       "0        Hello this is Dr Supawat from Eternity Clinic   \n",
       "1    today we are going to give you some knowledge ...   \n",
       "2                                    Into the genitals   \n",
       "3    Many patients say that the injection of foreig...   \n",
       "4                                    Into the genitals   \n",
       "..                                                 ...   \n",
       "579               Because it s a special order from me   \n",
       "580                                 Take a closer look   \n",
       "581                      Please leave an answer within   \n",
       "582                                    Wednesday April   \n",
       "583                                                 at   \n",
       "\n",
       "                             trimmed_segment_path  \\\n",
       "0      data/sub/ScnwIYdmqYw_trimmed_segment_1.wav   \n",
       "1      data/sub/ScnwIYdmqYw_trimmed_segment_2.wav   \n",
       "2      data/sub/ScnwIYdmqYw_trimmed_segment_3.wav   \n",
       "3      data/sub/ScnwIYdmqYw_trimmed_segment_4.wav   \n",
       "4      data/sub/ScnwIYdmqYw_trimmed_segment_5.wav   \n",
       "..                                            ...   \n",
       "579  data/sub/GWXwTJM68hk_trimmed_segment_351.wav   \n",
       "580  data/sub/GWXwTJM68hk_trimmed_segment_352.wav   \n",
       "581  data/sub/GWXwTJM68hk_trimmed_segment_353.wav   \n",
       "582  data/sub/GWXwTJM68hk_trimmed_segment_354.wav   \n",
       "583  data/sub/GWXwTJM68hk_trimmed_segment_355.wav   \n",
       "\n",
       "                                            hypothesis  segment_duration  \n",
       "0        Hello, I'm Dr. Superwat from Eternity Clinic.             3.642  \n",
       "1     Today, I'm going to tell you about Synthetic ...             5.204  \n",
       "2                                           menopause.             2.000  \n",
       "3     many patients have also diagnosed that it's i...             4.426  \n",
       "4                                                                  0.967  \n",
       "..                                                 ...               ...  \n",
       "579        Especially when it comes to special events.             1.929  \n",
       "580                     Please take a good look at it.             1.781  \n",
       "581                                   ENG SUB by JayBL             1.787  \n",
       "582            ENG SUBBED BY GIRLS' GENERATION ENG SUB             2.389  \n",
       "583                                                                1.828  \n",
       "\n",
       "[584 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>reference</th>\n",
       "      <th>trimmed_segment_path</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>segment_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>699.707</td>\n",
       "      <td>701.432</td>\n",
       "      <td>There is no almond flakes left</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_306.wav</td>\n",
       "      <td>I don't feel tired at all.</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>701.448</td>\n",
       "      <td>703.174</td>\n",
       "      <td>Well it is good</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_307.wav</td>\n",
       "      <td>It's like...</td>\n",
       "      <td>1.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>703.198</td>\n",
       "      <td>705.174</td>\n",
       "      <td>so milky it s so fine Yes</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_308.wav</td>\n",
       "      <td>It's like milk.</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>705.206</td>\n",
       "      <td>706.564</td>\n",
       "      <td>It s fine almond milk</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_309.wav</td>\n",
       "      <td>Thank you for watching.</td>\n",
       "      <td>1.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>706.589</td>\n",
       "      <td>707.799</td>\n",
       "      <td>So awesome So hot</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_310.wav</td>\n",
       "      <td>Very hot!</td>\n",
       "      <td>1.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>707.831</td>\n",
       "      <td>709.245</td>\n",
       "      <td>How many points</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_311.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>710.073</td>\n",
       "      <td>711.385</td>\n",
       "      <td>With point two as well</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_312.wav</td>\n",
       "      <td>1..2..3..</td>\n",
       "      <td>1.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>712.057</td>\n",
       "      <td>713.182</td>\n",
       "      <td>Where s the rest of the point</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_313.wav</td>\n",
       "      <td>See you next time.</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>713.206</td>\n",
       "      <td>714.689</td>\n",
       "      <td>It s too hot If it s a bit warm</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_314.wav</td>\n",
       "      <td>It's too hot.</td>\n",
       "      <td>1.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>714.714</td>\n",
       "      <td>716.648</td>\n",
       "      <td>I can drink it up in a minute Oh I see</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_315.wav</td>\n",
       "      <td>This the result of what I should do.</td>\n",
       "      <td>1.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>716.673</td>\n",
       "      <td>718.111</td>\n",
       "      <td>Tefal Ultrablend Boost You can buy Tefal Ultra...</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_316.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>718.127</td>\n",
       "      <td>720.856</td>\n",
       "      <td>Shopee at Shopee for a price of baht</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_317.wav</td>\n",
       "      <td>at Shopee for only 12,900 baht.</td>\n",
       "      <td>2.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>720.856</td>\n",
       "      <td>722.327</td>\n",
       "      <td>Get free Air fryer</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_318.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>722.327</td>\n",
       "      <td>723.853</td>\n",
       "      <td>and discount</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_319.wav</td>\n",
       "      <td>I'm gonna scroll down by 15%</td>\n",
       "      <td>1.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>723.853</td>\n",
       "      <td>726.329</td>\n",
       "      <td>Alright we ve finished both today s menus</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_320.wav</td>\n",
       "      <td>That's it for today's menu.</td>\n",
       "      <td>2.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>726.337</td>\n",
       "      <td>727.774</td>\n",
       "      <td>And it s very easy to make</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_321.wav</td>\n",
       "      <td>It's very easy.</td>\n",
       "      <td>1.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>727.798</td>\n",
       "      <td>730.509</td>\n",
       "      <td>Tefal Ultrablend Boost with this Tefal Ultrabl...</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_322.wav</td>\n",
       "      <td>Like this. The blue one is rose.</td>\n",
       "      <td>2.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>730.517</td>\n",
       "      <td>733.126</td>\n",
       "      <td>You can do both hot and cold preparations</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_323.wav</td>\n",
       "      <td>You can cook both hot and cold dishes.</td>\n",
       "      <td>2.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>733.158</td>\n",
       "      <td>735.439</td>\n",
       "      <td>Both of which are so delicious</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_324.wav</td>\n",
       "      <td>Both of the dishes are very delicious.</td>\n",
       "      <td>2.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>735.464</td>\n",
       "      <td>736.845</td>\n",
       "      <td>and so easy to make</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_325.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>736.861</td>\n",
       "      <td>739.564</td>\n",
       "      <td>If I can do it I m sure everyone can do it too</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_326.wav</td>\n",
       "      <td>If you can do it, everyone can do it.</td>\n",
       "      <td>2.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>739.580</td>\n",
       "      <td>740.907</td>\n",
       "      <td>You can try to do it</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_327.wav</td>\n",
       "      <td>Please look forward to it.</td>\n",
       "      <td>1.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>740.932</td>\n",
       "      <td>742.595</td>\n",
       "      <td>Don t forget to click Like</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_328.wav</td>\n",
       "      <td>And don't forget to click LIKE!</td>\n",
       "      <td>1.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>742.619</td>\n",
       "      <td>744.485</td>\n",
       "      <td>share and subscribe for me too</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_329.wav</td>\n",
       "      <td>If you like this video, don't forget to like,...</td>\n",
       "      <td>1.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>744.517</td>\n",
       "      <td>746.126</td>\n",
       "      <td>And whoever follow my recipe</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_330.wav</td>\n",
       "      <td>Who's going to do it after me?</td>\n",
       "      <td>1.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>746.149</td>\n",
       "      <td>747.344</td>\n",
       "      <td>how it turns up</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_331.wav</td>\n",
       "      <td>How do I look?</td>\n",
       "      <td>1.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>747.369</td>\n",
       "      <td>748.673</td>\n",
       "      <td>please share it to me</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_332.wav</td>\n",
       "      <td>Don't forget to like, share and subscribe to ...</td>\n",
       "      <td>1.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>748.689</td>\n",
       "      <td>749.775</td>\n",
       "      <td>I d love to see</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_333.wav</td>\n",
       "      <td>See you next time.</td>\n",
       "      <td>1.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>749.930</td>\n",
       "      <td>752.258</td>\n",
       "      <td>It s not over yet there s a game to play</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_334.wav</td>\n",
       "      <td>Thank you for watching.</td>\n",
       "      <td>2.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>752.344</td>\n",
       "      <td>754.071</td>\n",
       "      <td>Before I finish this EP</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_335.wav</td>\n",
       "      <td>Before end this EP.</td>\n",
       "      <td>1.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>754.096</td>\n",
       "      <td>756.477</td>\n",
       "      <td>I have a fun game for you to play</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_336.wav</td>\n",
       "      <td>They also have a lot of fun games for you to ...</td>\n",
       "      <td>2.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>756.509</td>\n",
       "      <td>758.789</td>\n",
       "      <td>As I said in the last EP</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_337.wav</td>\n",
       "      <td>As I told you in the last EP,</td>\n",
       "      <td>2.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>758.813</td>\n",
       "      <td>762.219</td>\n",
       "      <td>I ve already known the gender of my baby</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_338.wav</td>\n",
       "      <td>and if you are male or female</td>\n",
       "      <td>3.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>762.244</td>\n",
       "      <td>765.110</td>\n",
       "      <td>I d like you guys to guess that</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_339.wav</td>\n",
       "      <td>So I have to invite you guys to come and try ...</td>\n",
       "      <td>2.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>765.134</td>\n",
       "      <td>766.641</td>\n",
       "      <td>whether my baby</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_340.wav</td>\n",
       "      <td>So, what I'm trying to say is...</td>\n",
       "      <td>1.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>766.649</td>\n",
       "      <td>768.571</td>\n",
       "      <td>is a boy or a girl</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_341.wav</td>\n",
       "      <td>whether it's a boy or a girl.</td>\n",
       "      <td>1.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>768.587</td>\n",
       "      <td>770.524</td>\n",
       "      <td>If you guess it right I have a prize for you</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_342.wav</td>\n",
       "      <td>If you guess it right, you'll get a prize.</td>\n",
       "      <td>1.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>770.555</td>\n",
       "      <td>772.524</td>\n",
       "      <td>I ll show you the special prize</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_343.wav</td>\n",
       "      <td>I will show you later.</td>\n",
       "      <td>1.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>772.555</td>\n",
       "      <td>773.680</td>\n",
       "      <td>in next EP</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_344.wav</td>\n",
       "      <td>See you in the next episode.</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>773.704</td>\n",
       "      <td>776.179</td>\n",
       "      <td>along with announcing the list of lucky winners</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_345.wav</td>\n",
       "      <td>with the announcement of Shibuya shogunate.</td>\n",
       "      <td>2.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>776.204</td>\n",
       "      <td>778.492</td>\n",
       "      <td>Just leave a comment whether a boy or a girl</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_346.wav</td>\n",
       "      <td>If you think it's a girl or a boy, please lea...</td>\n",
       "      <td>2.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>778.517</td>\n",
       "      <td>779.685</td>\n",
       "      <td>For those people who guess it correctly</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_347.wav</td>\n",
       "      <td>I think it's a bit too much.</td>\n",
       "      <td>1.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>779.709</td>\n",
       "      <td>781.037</td>\n",
       "      <td>I ll have a lucky draw for</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_348.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>781.062</td>\n",
       "      <td>782.844</td>\n",
       "      <td>prizes in total It s a very special prize</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_349.wav</td>\n",
       "      <td>It's 10 baht per day.</td>\n",
       "      <td>1.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>782.869</td>\n",
       "      <td>784.258</td>\n",
       "      <td>that is not sold anywhere</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_350.wav</td>\n",
       "      <td>It's not for sale anywhere.</td>\n",
       "      <td>1.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>784.274</td>\n",
       "      <td>786.203</td>\n",
       "      <td>Because it s a special order from me</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_351.wav</td>\n",
       "      <td>Especially when it comes to special events.</td>\n",
       "      <td>1.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>786.235</td>\n",
       "      <td>788.016</td>\n",
       "      <td>Take a closer look</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_352.wav</td>\n",
       "      <td>Please take a good look at it.</td>\n",
       "      <td>1.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>788.329</td>\n",
       "      <td>790.116</td>\n",
       "      <td>Please leave an answer within</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_353.wav</td>\n",
       "      <td>ENG SUB by JayBL</td>\n",
       "      <td>1.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>790.141</td>\n",
       "      <td>792.530</td>\n",
       "      <td>Wednesday April</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_354.wav</td>\n",
       "      <td>ENG SUBBED BY GIRLS' GENERATION ENG SUB</td>\n",
       "      <td>2.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>792.555</td>\n",
       "      <td>794.383</td>\n",
       "      <td>at</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_355.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  start_time  end_time  \\\n",
       "534  GWXwTJM68hk     699.707   701.432   \n",
       "535  GWXwTJM68hk     701.448   703.174   \n",
       "536  GWXwTJM68hk     703.198   705.174   \n",
       "537  GWXwTJM68hk     705.206   706.564   \n",
       "538  GWXwTJM68hk     706.589   707.799   \n",
       "539  GWXwTJM68hk     707.831   709.245   \n",
       "540  GWXwTJM68hk     710.073   711.385   \n",
       "541  GWXwTJM68hk     712.057   713.182   \n",
       "542  GWXwTJM68hk     713.206   714.689   \n",
       "543  GWXwTJM68hk     714.714   716.648   \n",
       "544  GWXwTJM68hk     716.673   718.111   \n",
       "545  GWXwTJM68hk     718.127   720.856   \n",
       "546  GWXwTJM68hk     720.856   722.327   \n",
       "547  GWXwTJM68hk     722.327   723.853   \n",
       "548  GWXwTJM68hk     723.853   726.329   \n",
       "549  GWXwTJM68hk     726.337   727.774   \n",
       "550  GWXwTJM68hk     727.798   730.509   \n",
       "551  GWXwTJM68hk     730.517   733.126   \n",
       "552  GWXwTJM68hk     733.158   735.439   \n",
       "553  GWXwTJM68hk     735.464   736.845   \n",
       "554  GWXwTJM68hk     736.861   739.564   \n",
       "555  GWXwTJM68hk     739.580   740.907   \n",
       "556  GWXwTJM68hk     740.932   742.595   \n",
       "557  GWXwTJM68hk     742.619   744.485   \n",
       "558  GWXwTJM68hk     744.517   746.126   \n",
       "559  GWXwTJM68hk     746.149   747.344   \n",
       "560  GWXwTJM68hk     747.369   748.673   \n",
       "561  GWXwTJM68hk     748.689   749.775   \n",
       "562  GWXwTJM68hk     749.930   752.258   \n",
       "563  GWXwTJM68hk     752.344   754.071   \n",
       "564  GWXwTJM68hk     754.096   756.477   \n",
       "565  GWXwTJM68hk     756.509   758.789   \n",
       "566  GWXwTJM68hk     758.813   762.219   \n",
       "567  GWXwTJM68hk     762.244   765.110   \n",
       "568  GWXwTJM68hk     765.134   766.641   \n",
       "569  GWXwTJM68hk     766.649   768.571   \n",
       "570  GWXwTJM68hk     768.587   770.524   \n",
       "571  GWXwTJM68hk     770.555   772.524   \n",
       "572  GWXwTJM68hk     772.555   773.680   \n",
       "573  GWXwTJM68hk     773.704   776.179   \n",
       "574  GWXwTJM68hk     776.204   778.492   \n",
       "575  GWXwTJM68hk     778.517   779.685   \n",
       "576  GWXwTJM68hk     779.709   781.037   \n",
       "577  GWXwTJM68hk     781.062   782.844   \n",
       "578  GWXwTJM68hk     782.869   784.258   \n",
       "579  GWXwTJM68hk     784.274   786.203   \n",
       "580  GWXwTJM68hk     786.235   788.016   \n",
       "581  GWXwTJM68hk     788.329   790.116   \n",
       "582  GWXwTJM68hk     790.141   792.530   \n",
       "583  GWXwTJM68hk     792.555   794.383   \n",
       "\n",
       "                                             reference  \\\n",
       "534                     There is no almond flakes left   \n",
       "535                                    Well it is good   \n",
       "536                          so milky it s so fine Yes   \n",
       "537                              It s fine almond milk   \n",
       "538                                  So awesome So hot   \n",
       "539                                    How many points   \n",
       "540                             With point two as well   \n",
       "541                      Where s the rest of the point   \n",
       "542                    It s too hot If it s a bit warm   \n",
       "543             I can drink it up in a minute Oh I see   \n",
       "544  Tefal Ultrablend Boost You can buy Tefal Ultra...   \n",
       "545               Shopee at Shopee for a price of baht   \n",
       "546                                 Get free Air fryer   \n",
       "547                                       and discount   \n",
       "548          Alright we ve finished both today s menus   \n",
       "549                         And it s very easy to make   \n",
       "550  Tefal Ultrablend Boost with this Tefal Ultrabl...   \n",
       "551          You can do both hot and cold preparations   \n",
       "552                     Both of which are so delicious   \n",
       "553                                and so easy to make   \n",
       "554     If I can do it I m sure everyone can do it too   \n",
       "555                               You can try to do it   \n",
       "556                         Don t forget to click Like   \n",
       "557                     share and subscribe for me too   \n",
       "558                       And whoever follow my recipe   \n",
       "559                                    how it turns up   \n",
       "560                              please share it to me   \n",
       "561                                    I d love to see   \n",
       "562           It s not over yet there s a game to play   \n",
       "563                            Before I finish this EP   \n",
       "564                  I have a fun game for you to play   \n",
       "565                           As I said in the last EP   \n",
       "566           I ve already known the gender of my baby   \n",
       "567                    I d like you guys to guess that   \n",
       "568                                    whether my baby   \n",
       "569                                 is a boy or a girl   \n",
       "570       If you guess it right I have a prize for you   \n",
       "571                    I ll show you the special prize   \n",
       "572                                         in next EP   \n",
       "573    along with announcing the list of lucky winners   \n",
       "574       Just leave a comment whether a boy or a girl   \n",
       "575            For those people who guess it correctly   \n",
       "576                         I ll have a lucky draw for   \n",
       "577          prizes in total It s a very special prize   \n",
       "578                          that is not sold anywhere   \n",
       "579               Because it s a special order from me   \n",
       "580                                 Take a closer look   \n",
       "581                      Please leave an answer within   \n",
       "582                                    Wednesday April   \n",
       "583                                                 at   \n",
       "\n",
       "                             trimmed_segment_path  \\\n",
       "534  data/sub/GWXwTJM68hk_trimmed_segment_306.wav   \n",
       "535  data/sub/GWXwTJM68hk_trimmed_segment_307.wav   \n",
       "536  data/sub/GWXwTJM68hk_trimmed_segment_308.wav   \n",
       "537  data/sub/GWXwTJM68hk_trimmed_segment_309.wav   \n",
       "538  data/sub/GWXwTJM68hk_trimmed_segment_310.wav   \n",
       "539  data/sub/GWXwTJM68hk_trimmed_segment_311.wav   \n",
       "540  data/sub/GWXwTJM68hk_trimmed_segment_312.wav   \n",
       "541  data/sub/GWXwTJM68hk_trimmed_segment_313.wav   \n",
       "542  data/sub/GWXwTJM68hk_trimmed_segment_314.wav   \n",
       "543  data/sub/GWXwTJM68hk_trimmed_segment_315.wav   \n",
       "544  data/sub/GWXwTJM68hk_trimmed_segment_316.wav   \n",
       "545  data/sub/GWXwTJM68hk_trimmed_segment_317.wav   \n",
       "546  data/sub/GWXwTJM68hk_trimmed_segment_318.wav   \n",
       "547  data/sub/GWXwTJM68hk_trimmed_segment_319.wav   \n",
       "548  data/sub/GWXwTJM68hk_trimmed_segment_320.wav   \n",
       "549  data/sub/GWXwTJM68hk_trimmed_segment_321.wav   \n",
       "550  data/sub/GWXwTJM68hk_trimmed_segment_322.wav   \n",
       "551  data/sub/GWXwTJM68hk_trimmed_segment_323.wav   \n",
       "552  data/sub/GWXwTJM68hk_trimmed_segment_324.wav   \n",
       "553  data/sub/GWXwTJM68hk_trimmed_segment_325.wav   \n",
       "554  data/sub/GWXwTJM68hk_trimmed_segment_326.wav   \n",
       "555  data/sub/GWXwTJM68hk_trimmed_segment_327.wav   \n",
       "556  data/sub/GWXwTJM68hk_trimmed_segment_328.wav   \n",
       "557  data/sub/GWXwTJM68hk_trimmed_segment_329.wav   \n",
       "558  data/sub/GWXwTJM68hk_trimmed_segment_330.wav   \n",
       "559  data/sub/GWXwTJM68hk_trimmed_segment_331.wav   \n",
       "560  data/sub/GWXwTJM68hk_trimmed_segment_332.wav   \n",
       "561  data/sub/GWXwTJM68hk_trimmed_segment_333.wav   \n",
       "562  data/sub/GWXwTJM68hk_trimmed_segment_334.wav   \n",
       "563  data/sub/GWXwTJM68hk_trimmed_segment_335.wav   \n",
       "564  data/sub/GWXwTJM68hk_trimmed_segment_336.wav   \n",
       "565  data/sub/GWXwTJM68hk_trimmed_segment_337.wav   \n",
       "566  data/sub/GWXwTJM68hk_trimmed_segment_338.wav   \n",
       "567  data/sub/GWXwTJM68hk_trimmed_segment_339.wav   \n",
       "568  data/sub/GWXwTJM68hk_trimmed_segment_340.wav   \n",
       "569  data/sub/GWXwTJM68hk_trimmed_segment_341.wav   \n",
       "570  data/sub/GWXwTJM68hk_trimmed_segment_342.wav   \n",
       "571  data/sub/GWXwTJM68hk_trimmed_segment_343.wav   \n",
       "572  data/sub/GWXwTJM68hk_trimmed_segment_344.wav   \n",
       "573  data/sub/GWXwTJM68hk_trimmed_segment_345.wav   \n",
       "574  data/sub/GWXwTJM68hk_trimmed_segment_346.wav   \n",
       "575  data/sub/GWXwTJM68hk_trimmed_segment_347.wav   \n",
       "576  data/sub/GWXwTJM68hk_trimmed_segment_348.wav   \n",
       "577  data/sub/GWXwTJM68hk_trimmed_segment_349.wav   \n",
       "578  data/sub/GWXwTJM68hk_trimmed_segment_350.wav   \n",
       "579  data/sub/GWXwTJM68hk_trimmed_segment_351.wav   \n",
       "580  data/sub/GWXwTJM68hk_trimmed_segment_352.wav   \n",
       "581  data/sub/GWXwTJM68hk_trimmed_segment_353.wav   \n",
       "582  data/sub/GWXwTJM68hk_trimmed_segment_354.wav   \n",
       "583  data/sub/GWXwTJM68hk_trimmed_segment_355.wav   \n",
       "\n",
       "                                            hypothesis  segment_duration  \n",
       "534                         I don't feel tired at all.             1.725  \n",
       "535                                       It's like...             1.726  \n",
       "536                                    It's like milk.             1.976  \n",
       "537                            Thank you for watching.             1.358  \n",
       "538                                          Very hot!             1.210  \n",
       "539                                                                1.414  \n",
       "540                                          1..2..3..             1.312  \n",
       "541                                 See you next time.             1.125  \n",
       "542                                      It's too hot.             1.483  \n",
       "543               This the result of what I should do.             1.934  \n",
       "544                                                                1.438  \n",
       "545                    at Shopee for only 12,900 baht.             2.729  \n",
       "546                                                                1.471  \n",
       "547                       I'm gonna scroll down by 15%             1.526  \n",
       "548                        That's it for today's menu.             2.476  \n",
       "549                                    It's very easy.             1.437  \n",
       "550                   Like this. The blue one is rose.             2.711  \n",
       "551             You can cook both hot and cold dishes.             2.609  \n",
       "552             Both of the dishes are very delicious.             2.281  \n",
       "553                                                                1.381  \n",
       "554              If you can do it, everyone can do it.             2.703  \n",
       "555                         Please look forward to it.             1.327  \n",
       "556                    And don't forget to click LIKE!             1.663  \n",
       "557   If you like this video, don't forget to like,...             1.866  \n",
       "558                     Who's going to do it after me?             1.609  \n",
       "559                                     How do I look?             1.195  \n",
       "560   Don't forget to like, share and subscribe to ...             1.304  \n",
       "561                                 See you next time.             1.086  \n",
       "562                            Thank you for watching.             2.328  \n",
       "563                                Before end this EP.             1.727  \n",
       "564   They also have a lot of fun games for you to ...             2.381  \n",
       "565                      As I told you in the last EP,             2.280  \n",
       "566                      and if you are male or female             3.406  \n",
       "567   So I have to invite you guys to come and try ...             2.866  \n",
       "568                   So, what I'm trying to say is...             1.507  \n",
       "569                      whether it's a boy or a girl.             1.922  \n",
       "570         If you guess it right, you'll get a prize.             1.937  \n",
       "571                             I will show you later.             1.969  \n",
       "572                       See you in the next episode.             1.125  \n",
       "573        with the announcement of Shibuya shogunate.             2.475  \n",
       "574   If you think it's a girl or a boy, please lea...             2.288  \n",
       "575                       I think it's a bit too much.             1.168  \n",
       "576                                                                1.328  \n",
       "577                              It's 10 baht per day.             1.782  \n",
       "578                        It's not for sale anywhere.             1.389  \n",
       "579        Especially when it comes to special events.             1.929  \n",
       "580                     Please take a good look at it.             1.781  \n",
       "581                                   ENG SUB by JayBL             1.787  \n",
       "582            ENG SUBBED BY GIRLS' GENERATION ENG SUB             2.389  \n",
       "583                                                                1.828  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio time (s): 1227.7599999999993\n"
     ]
    }
   ],
   "source": [
    "print(\"Total audio time (s):\", combined_df['segment_duration'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhuser/Desktop/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"biodatlab/whisper-th-medium-combined\"  # see alternative model names below\n",
    "lang = \"th\"\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=MODEL_NAME,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_transcription_finetuned_asr(row, pipe):\n",
    "    segment_wavfile = row['trimmed_segment_path']\n",
    "    transcription = pipe(segment_wavfile, generate_kwargs={\"language\":\"<|th|>\", \"task\":\"translate\"}, batch_size=16)[\"text\"]\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "transcriptions_finetuned = combined_df.apply(lambda row: map_transcription_finetuned_asr(row, pipe), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Hello, I'm Dr. Suprawath from Eternity Clinic.\n",
       "1       Today, we will give you some information abou...\n",
       "2                                         into the type.\n",
       "3       Many people have been taken to the treatment ...\n",
       "4                               in the type of tomatoes,\n",
       "                             ...                        \n",
       "579                       especially for special events.\n",
       "580                                     Watch carefully.\n",
       "581                           I'm going to the bathroom.\n",
       "582                                     I'm going to the\n",
       "583                                   Add 1 Tbsp. of oil\n",
       "Length: 584, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>reference</th>\n",
       "      <th>trimmed_segment_path</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>segment_duration</th>\n",
       "      <th>hypothesis_finetuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>0.708</td>\n",
       "      <td>4.350</td>\n",
       "      <td>Hello this is Dr Supawat from Eternity Clinic</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_1.wav</td>\n",
       "      <td>Hello, I'm Dr. Superwat from Eternity Clinic.</td>\n",
       "      <td>3.642</td>\n",
       "      <td>Hello, I'm Dr. Suprawath from Eternity Clinic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>4.350</td>\n",
       "      <td>9.554</td>\n",
       "      <td>today we are going to give you some knowledge ...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_2.wav</td>\n",
       "      <td>Today, I'm going to tell you about Synthetic ...</td>\n",
       "      <td>5.204</td>\n",
       "      <td>Today, we will give you some information abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>9.554</td>\n",
       "      <td>11.554</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_3.wav</td>\n",
       "      <td>menopause.</td>\n",
       "      <td>2.000</td>\n",
       "      <td>into the type.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>21.000</td>\n",
       "      <td>25.426</td>\n",
       "      <td>Many patients say that the injection of foreig...</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_4.wav</td>\n",
       "      <td>many patients have also diagnosed that it's i...</td>\n",
       "      <td>4.426</td>\n",
       "      <td>Many people have been taken to the treatment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ScnwIYdmqYw</td>\n",
       "      <td>25.426</td>\n",
       "      <td>26.393</td>\n",
       "      <td>Into the genitals</td>\n",
       "      <td>data/sub/ScnwIYdmqYw_trimmed_segment_5.wav</td>\n",
       "      <td></td>\n",
       "      <td>0.967</td>\n",
       "      <td>in the type of tomatoes,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>784.274</td>\n",
       "      <td>786.203</td>\n",
       "      <td>Because it s a special order from me</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_351.wav</td>\n",
       "      <td>Especially when it comes to special events.</td>\n",
       "      <td>1.929</td>\n",
       "      <td>especially for special events.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>786.235</td>\n",
       "      <td>788.016</td>\n",
       "      <td>Take a closer look</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_352.wav</td>\n",
       "      <td>Please take a good look at it.</td>\n",
       "      <td>1.781</td>\n",
       "      <td>Watch carefully.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>788.329</td>\n",
       "      <td>790.116</td>\n",
       "      <td>Please leave an answer within</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_353.wav</td>\n",
       "      <td>ENG SUB by JayBL</td>\n",
       "      <td>1.787</td>\n",
       "      <td>I'm going to the bathroom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>790.141</td>\n",
       "      <td>792.530</td>\n",
       "      <td>Wednesday April</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_354.wav</td>\n",
       "      <td>ENG SUBBED BY GIRLS' GENERATION ENG SUB</td>\n",
       "      <td>2.389</td>\n",
       "      <td>I'm going to the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>GWXwTJM68hk</td>\n",
       "      <td>792.555</td>\n",
       "      <td>794.383</td>\n",
       "      <td>at</td>\n",
       "      <td>data/sub/GWXwTJM68hk_trimmed_segment_355.wav</td>\n",
       "      <td></td>\n",
       "      <td>1.828</td>\n",
       "      <td>Add 1 Tbsp. of oil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  start_time  end_time  \\\n",
       "0    ScnwIYdmqYw       0.708     4.350   \n",
       "1    ScnwIYdmqYw       4.350     9.554   \n",
       "2    ScnwIYdmqYw       9.554    11.554   \n",
       "3    ScnwIYdmqYw      21.000    25.426   \n",
       "4    ScnwIYdmqYw      25.426    26.393   \n",
       "..           ...         ...       ...   \n",
       "579  GWXwTJM68hk     784.274   786.203   \n",
       "580  GWXwTJM68hk     786.235   788.016   \n",
       "581  GWXwTJM68hk     788.329   790.116   \n",
       "582  GWXwTJM68hk     790.141   792.530   \n",
       "583  GWXwTJM68hk     792.555   794.383   \n",
       "\n",
       "                                             reference  \\\n",
       "0        Hello this is Dr Supawat from Eternity Clinic   \n",
       "1    today we are going to give you some knowledge ...   \n",
       "2                                    Into the genitals   \n",
       "3    Many patients say that the injection of foreig...   \n",
       "4                                    Into the genitals   \n",
       "..                                                 ...   \n",
       "579               Because it s a special order from me   \n",
       "580                                 Take a closer look   \n",
       "581                      Please leave an answer within   \n",
       "582                                    Wednesday April   \n",
       "583                                                 at   \n",
       "\n",
       "                             trimmed_segment_path  \\\n",
       "0      data/sub/ScnwIYdmqYw_trimmed_segment_1.wav   \n",
       "1      data/sub/ScnwIYdmqYw_trimmed_segment_2.wav   \n",
       "2      data/sub/ScnwIYdmqYw_trimmed_segment_3.wav   \n",
       "3      data/sub/ScnwIYdmqYw_trimmed_segment_4.wav   \n",
       "4      data/sub/ScnwIYdmqYw_trimmed_segment_5.wav   \n",
       "..                                            ...   \n",
       "579  data/sub/GWXwTJM68hk_trimmed_segment_351.wav   \n",
       "580  data/sub/GWXwTJM68hk_trimmed_segment_352.wav   \n",
       "581  data/sub/GWXwTJM68hk_trimmed_segment_353.wav   \n",
       "582  data/sub/GWXwTJM68hk_trimmed_segment_354.wav   \n",
       "583  data/sub/GWXwTJM68hk_trimmed_segment_355.wav   \n",
       "\n",
       "                                            hypothesis  segment_duration  \\\n",
       "0        Hello, I'm Dr. Superwat from Eternity Clinic.             3.642   \n",
       "1     Today, I'm going to tell you about Synthetic ...             5.204   \n",
       "2                                           menopause.             2.000   \n",
       "3     many patients have also diagnosed that it's i...             4.426   \n",
       "4                                                                  0.967   \n",
       "..                                                 ...               ...   \n",
       "579        Especially when it comes to special events.             1.929   \n",
       "580                     Please take a good look at it.             1.781   \n",
       "581                                   ENG SUB by JayBL             1.787   \n",
       "582            ENG SUBBED BY GIRLS' GENERATION ENG SUB             2.389   \n",
       "583                                                                1.828   \n",
       "\n",
       "                                  hypothesis_finetuned  \n",
       "0       Hello, I'm Dr. Suprawath from Eternity Clinic.  \n",
       "1     Today, we will give you some information abou...  \n",
       "2                                       into the type.  \n",
       "3     Many people have been taken to the treatment ...  \n",
       "4                             in the type of tomatoes,  \n",
       "..                                                 ...  \n",
       "579                     especially for special events.  \n",
       "580                                   Watch carefully.  \n",
       "581                         I'm going to the bathroom.  \n",
       "582                                   I'm going to the  \n",
       "583                                 Add 1 Tbsp. of oil  \n",
       "\n",
       "[584 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['hypothesis_finetuned'] = transcriptions_finetuned\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate: 0.9378796245168415\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=combined_df['hypothesis'], references=combined_df['reference'])\n",
    "print(\"Word Error Rate:\", wer_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (Finetuned): 0.9350684196404615\n"
     ]
    }
   ],
   "source": [
    "wer_score_finetuned = wer.compute(predictions=combined_df['hypothesis'], references=transcriptions_finetuned)\n",
    "print(\"Word Error Rate (Finetuned):\", wer_score_finetuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meteor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def strip_punctuation(text):\n",
    "    # Create a translation table that maps each punctuation character to None\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Use the translation table to remove all punctuation from the text\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['hypothesis'] = combined_df['hypothesis'].apply(strip_punctuation).apply(lambda x : x.strip())\n",
    "combined_df['hypothesis_finetuned'] = combined_df['hypothesis_finetuned'].apply(strip_punctuation).apply(lambda x : x.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dhuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dhuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/dhuser/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate \n",
    "\n",
    "meteor = evaluate.load('meteor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    584.000000\n",
       "mean       0.231022\n",
       "std        0.267411\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.125000\n",
       "75%        0.405705\n",
       "max        0.997685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_meteor(row, hypothesis_column, reference_column):\n",
    "    meteor_score = meteor.compute(predictions=[row[hypothesis_column],], references=[row[reference_column],])\n",
    "    return meteor_score['meteor']\n",
    "\n",
    "meteor_scores_whisper = combined_df.apply(lambda row : compute_meteor(row, 'hypothesis', 'reference'), axis = 1)\n",
    "meteor_scores_whisper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    584.000000\n",
       "mean       0.248323\n",
       "std        0.240214\n",
       "min        0.000000\n",
       "25%        0.064935\n",
       "50%        0.172414\n",
       "75%        0.385483\n",
       "max        0.997685\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteor_scores_whisper_finetuned = combined_df.apply(lambda row : compute_meteor(row, 'hypothesis_finetuned', 'reference'), axis = 1)\n",
    "meteor_scores_whisper_finetuned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    584.000000\n",
       "mean       0.035520\n",
       "std        0.142855\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_bleu(row, hypothesis_column, reference_column):\n",
    "    # Extract the hypothesis and reference\n",
    "    hypothesis = row[hypothesis_column]\n",
    "    reference = row[reference_column]\n",
    "\n",
    "    # Check for empty hypothesis or reference\n",
    "    if not hypothesis or not reference:\n",
    "        return 0.0\n",
    "\n",
    "    # Compute BLEU score\n",
    "    bleu_score = bleu.compute(predictions=[hypothesis], references=[[reference]])\n",
    "    return bleu_score['bleu']\n",
    "\n",
    "bleu_scores_whisper = combined_df.apply(lambda row : compute_bleu(row, 'hypothesis', 'reference'), axis = 1)\n",
    "bleu_scores_whisper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    584.000000\n",
       "mean       0.033423\n",
       "std        0.137551\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_whisper_finetuned = combined_df.apply(lambda row : compute_bleu(row, 'hypothesis_finetuned', 'reference'), axis = 1)\n",
    "bleu_scores_whisper_finetuned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Audio Embeddings from Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper.audio import load_audio, pad_or_trim, log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = log_mel_spectrogram(\"data/sub/ScnwIYdmqYw_trimmed_segment_1.wav\", 80)\n",
    "mel2 = log_mel_spectrogram(\"data/sub/ScnwIYdmqYw_trimmed_segment_2.wav\", 80)\n",
    "\n",
    "padded_mel = pad_or_trim(mel, 3000).to(\"cuda\")\n",
    "padded_mel2 = pad_or_trim(mel2, 3000).to(\"cuda\")\n",
    "batch_tensor = torch.stack([padded_mel2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/sub/ScnwIYdmqYw_trimmed_segment_2.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtranslate_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/.venv/lib/python3.10/site-packages/whisper/transcribe.py:276\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    274\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m mel[:, seek : seek \u001b[38;5;241m+\u001b[39m segment_size]\n\u001b[1;32m    275\u001b[0m segment_duration \u001b[38;5;241m=\u001b[39m segment_size \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE\n\u001b[0;32m--> 276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m \u001b[43mpad_or_trim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_FRAMES\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m    279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m decode_with_fallback(mel_segment)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "model.transcribe(\"data/sub/ScnwIYdmqYw_trimmed_segment_2.wav\", **translate_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
